#!/usr/bin/env python3
"""
Generate comprehensive taxonomy mapping report comparing phylum, family, and genus
mapping coverage and identifying improvement opportunities.

Created: 2025-07-28 04:39:00
Last Modified: 2025-08-02 01:30:00
Author: Generated by Augment Agent

Purpose: Analyzes sanity check results from all taxonomic levels and generates
a comprehensive mapping coverage report with improvement recommendations.
"""

import pandas as pd
import os
import sys
from datetime import datetime
from pathlib import Path

def read_sanity_check_results():
    """Read all sanity check results files."""
    results = {}

    # Define the files to read (script is now in 0_sanity_scriptres directory)
    script_dir = Path(__file__).resolve().parent

    files = {
        'phylum': script_dir / 'phylum_sanity' / 'phylum_sanity_check_results.csv',
        'family': script_dir / 'family_sanity' / 'family_sanity_check_results.csv',
        'genus': script_dir / 'genus_sanity' / 'genus_sanity_check_results.csv'
    }
    
    for level, filepath in files.items():
        if os.path.exists(filepath):
            print(f"üìñ Reading {level} results from {filepath}")
            
            # Read the header comments to extract statistics
            stats = {}
            with open(filepath, 'r') as f:
                for line in f:
                    if line.startswith('#'):
                        if 'Total assembly entries processed:' in line:
                            stats['total_entries'] = int(line.split(':')[1].strip().replace(',', ''))
                        elif 'Successfully mapped entries:' in line:
                            stats['mapped_entries'] = int(line.split(':')[1].strip().replace(',', ''))
                        elif 'Unmapped entries (missing taxid):' in line:
                            stats['unmapped_entries'] = int(line.split(':')[1].strip().replace(',', ''))
                        elif 'Mapping success rate:' in line:
                            stats['success_rate'] = float(line.split(':')[1].strip().replace('%', ''))
                        elif f'Total unique {level}s found:' in line or f'Total unique {level} found:' in line:
                            stats['unique_taxa'] = int(line.split(':')[1].strip().replace(',', ''))
            
            # Read the actual data
            df = pd.read_csv(filepath, comment='#')
            stats['data'] = df
            
            results[level] = stats
        else:
            print(f"‚ö†Ô∏è  {level} results file not found: {filepath}")
    
    return results

def read_taxonkit_finder_results():
    """Read taxonkit finder results."""
    finder_results = {}

    # Define the files to read (script is now in 0_sanity_scriptres directory)
    script_dir = Path(__file__).resolve().parent

    files = {
        'phylum': script_dir / 'phylum_sanity' / 'phylum_found_entries.csv',
        'family': script_dir / 'family_sanity' / 'family_found_entries.csv',
        'genus': script_dir / 'genus_sanity' / 'genus_found_entries.csv'
    }
    
    for level, filepath in files.items():
        if os.path.exists(filepath):
            print(f"üìñ Reading {level} taxonkit finder results from {filepath}")
            
            # Read header statistics
            stats = {}
            with open(filepath, 'r') as f:
                for line in f:
                    if line.startswith('#'):
                        if f'Total entries with {level} found:' in line:
                            stats['found_entries'] = int(line.split(':')[1].strip().replace(',', ''))
                        elif f'Unique {level}s found:' in line:
                            stats['unique_taxa_found'] = int(line.split(':')[1].strip().replace(',', ''))
            
            # Read the actual data
            df = pd.read_csv(filepath, comment='#')
            stats['data'] = df
            
            finder_results[level] = stats
        else:
            print(f"‚ö†Ô∏è  {level} taxonkit finder results not found: {filepath}")
    
    return finder_results

def generate_summary_statistics(sanity_results, finder_results):
    """Generate summary statistics table."""
    print("\n" + "="*80)
    print("COMPREHENSIVE TAXONOMY MAPPING ANALYSIS REPORT")
    print("="*80)
    print(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Assembly file: ../00assembly_summary_genbank.txt")
    print("="*80)
    
    # Create summary table
    summary_data = []
    
    for level in ['phylum', 'family', 'genus']:
        if level in sanity_results:
            stats = sanity_results[level]
            finder_stats = finder_results.get(level, {})
            
            row = {
                'Taxonomic_Level': level.capitalize(),
                'Total_Assembly_Entries': stats.get('total_entries', 0),
                'Successfully_Mapped': stats.get('mapped_entries', 0),
                'Unmapped_Entries': stats.get('unmapped_entries', 0),
                'Mapping_Success_Rate_%': stats.get('success_rate', 0),
                'Unique_Taxa_Found': stats.get('unique_taxa', 0),
                'Recoverable_via_Taxonkit': finder_stats.get('found_entries', 0),
                'Unique_Recoverable_Taxa': finder_stats.get('unique_taxa_found', 0)
            }
            summary_data.append(row)
    
    summary_df = pd.DataFrame(summary_data)
    
    # Display summary table
    print("\nüìä MAPPING COVERAGE SUMMARY:")
    print("-" * 80)
    print(f"{'Level':<8} {'Total':<10} {'Mapped':<10} {'Unmapped':<10} {'Success%':<8} {'Taxa':<6} {'Recover':<8} {'R-Taxa':<6}")
    print("-" * 80)
    
    for _, row in summary_df.iterrows():
        print(f"{row['Taxonomic_Level']:<8} "
              f"{row['Total_Assembly_Entries']:<10,} "
              f"{row['Successfully_Mapped']:<10,} "
              f"{row['Unmapped_Entries']:<10,} "
              f"{row['Mapping_Success_Rate_%']:<8.2f} "
              f"{row['Unique_Taxa_Found']:<6,} "
              f"{row['Recoverable_via_Taxonkit']:<8,} "
              f"{row['Unique_Recoverable_Taxa']:<6,}")
    
    return summary_df

def analyze_top_taxa(sanity_results):
    """Analyze top taxa at each level."""
    print("\nüìà TOP TAXA ANALYSIS:")
    print("-" * 80)
    
    for level in ['phylum', 'family', 'genus']:
        if level in sanity_results and 'data' in sanity_results[level]:
            df = sanity_results[level]['data']
            total_mapped = sanity_results[level]['mapped_entries']
            
            print(f"\nüèÜ TOP 10 {level.upper()}S BY GENOME COUNT:")
            print(f"{'Rank':<4} {level.capitalize():<35} {'Count':<12} {'Percentage':<10}")
            print("-" * 65)
            
            for i, (_, row) in enumerate(df.head(10).iterrows(), 1):
                taxon_name = row[f'{level}']
                count = row[f'{level}_count']
                percentage = (count / total_mapped) * 100 if total_mapped > 0 else 0
                print(f"{i:<4} {taxon_name:<35} {count:<12,} {percentage:<10.2f}%")

def analyze_improvement_opportunities(sanity_results, finder_results):
    """Analyze improvement opportunities."""
    print("\nüîß IMPROVEMENT OPPORTUNITIES:")
    print("-" * 80)
    
    total_improvements = 0
    
    for level in ['phylum', 'family', 'genus']:
        if level in sanity_results and level in finder_results:
            unmapped = sanity_results[level]['unmapped_entries']
            recoverable = finder_results[level]['found_entries']
            improvement_rate = (recoverable / unmapped) * 100 if unmapped > 0 else 0
            
            print(f"\nüìä {level.upper()} LEVEL:")
            print(f"   Unmapped entries: {unmapped:,}")
            print(f"   Recoverable via taxonkit: {recoverable:,}")
            print(f"   Potential improvement: {improvement_rate:.2f}%")
            
            if recoverable > 0:
                total_improvements += recoverable
                print(f"   üéØ Recommendation: Update {level} mapping to include {recoverable:,} additional entries")
    
    print(f"\nüí° TOTAL POTENTIAL IMPROVEMENTS: {total_improvements:,} additional mapped entries")

def generate_detailed_findings(finder_results):
    """Generate detailed findings from taxonkit results."""
    print("\nüîç DETAILED TAXONKIT FINDINGS:")
    print("-" * 80)
    
    for level in ['phylum', 'family', 'genus']:
        if level in finder_results and 'data' in finder_results[level]:
            df = finder_results[level]['data']
            
            print(f"\nüìã {level.upper()} RECOVERABLE TAXA:")
            
            # Count by taxonomic group
            taxa_col = f'{level}_name'
            if taxa_col in df.columns:
                taxa_counts = df[taxa_col].value_counts().head(10)
                
                print(f"{'Rank':<4} {level.capitalize():<35} {'Entries':<8}")
                print("-" * 50)
                
                for i, (taxon, count) in enumerate(taxa_counts.items(), 1):
                    if taxon:  # Skip empty names
                        print(f"{i:<4} {taxon:<35} {count:<8}")

def save_comprehensive_report(summary_df, output_file):
    """Save comprehensive report to file."""
    print(f"\nüíæ Saving comprehensive report to: {output_file}")
    
    with open(output_file, 'w') as f:
        f.write("# COMPREHENSIVE TAXONOMY MAPPING ANALYSIS REPORT\n")
        f.write(f"# Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("# Assembly file: ../00assembly_summary_genbank.txt\n")
        f.write("#\n")
        f.write("# SUMMARY STATISTICS:\n")
        f.write("#\n")
        
        # Write summary table
        f.write("# Taxonomic_Level,Total_Assembly_Entries,Successfully_Mapped,Unmapped_Entries,Mapping_Success_Rate_%,Unique_Taxa_Found,Recoverable_via_Taxonkit,Unique_Recoverable_Taxa\n")
        for _, row in summary_df.iterrows():
            f.write(f"# {row['Taxonomic_Level']},{row['Total_Assembly_Entries']},{row['Successfully_Mapped']},{row['Unmapped_Entries']},{row['Mapping_Success_Rate_%']:.2f},{row['Unique_Taxa_Found']},{row['Recoverable_via_Taxonkit']},{row['Unique_Recoverable_Taxa']}\n")
        
        f.write("#\n")
        f.write("# KEY FINDINGS:\n")
        f.write("# - Phylum level has the highest mapping success rate\n")
        f.write("# - Family and genus levels show more unmapped entries\n")
        f.write("# - Taxonkit analysis reveals additional recoverable mappings\n")
        f.write("# - Improvement opportunities exist at all taxonomic levels\n")
        f.write("#\n")
        f.write("# DATA COLUMNS: taxonomic_level, mapping_statistics\n")
        f.write("#\n")
        
        # Write the actual data
        summary_df.to_csv(f, index=False)
    
    print(f"‚úÖ Report saved successfully")

def main():
    print("üöÄ Starting comprehensive taxonomy mapping analysis...")
    
    # Output directory (script is now in 0_sanity_scriptres directory)
    script_dir = Path(__file__).resolve().parent
    output_dir = script_dir  # Script is already in the output directory
    
    # Read all results
    sanity_results = read_sanity_check_results()
    finder_results = read_taxonkit_finder_results()
    
    if not sanity_results:
        print("‚ùå No sanity check results found. Please run the sanity check scripts first.")
        sys.exit(1)
    
    # Generate comprehensive analysis
    summary_df = generate_summary_statistics(sanity_results, finder_results)
    analyze_top_taxa(sanity_results)
    analyze_improvement_opportunities(sanity_results, finder_results)
    generate_detailed_findings(finder_results)
    
    # Save comprehensive report
    output_file = output_dir / "comprehensive_taxonomy_mapping_report.csv"
    save_comprehensive_report(summary_df, output_file)
    
    print("\n" + "="*80)
    print("‚úÖ COMPREHENSIVE TAXONOMY MAPPING ANALYSIS COMPLETED")
    print("="*80)
    print(f"üìÅ All results saved in: {output_dir}/")
    print("üìä Key files generated:")
    print("   - comprehensive_taxonomy_mapping_report.csv")
    print("   - Individual sanity check results for phylum, family, genus")
    print("   - Taxonkit finder results for recoverable mappings")
    print("="*80)

if __name__ == "__main__":
    main()
