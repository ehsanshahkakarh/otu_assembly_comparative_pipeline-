#!/usr/bin/env python3
"""
Sanity check script to parse assembly file and group by phylum with counts.
Uses taxid_to_phylum.csv as input for phylum mapping.

Created: 2025-07-28 03:48:00
Last Modified: 2025-08-02 01:38:00
Author: Generated by Augment Agent

Purpose: Maps NCBI assembly entries to phylum-level taxonomy and identifies unmapped entries.
"""

import pandas as pd
import sys
from collections import Counter
from tqdm import tqdm
from pathlib import Path

def load_taxid_to_phylum_mapping(mapping_file):
    """Load the taxid to phylum mapping from CSV file."""
    print("Loading taxid to phylum mapping...")
    try:
        mapping_df = pd.read_csv(mapping_file)
        print(f"Loaded {len(mapping_df)} taxid mappings")
        # Filter out any non-numeric taxids (like header strings that might have been included)
        mapping_df = mapping_df[pd.to_numeric(mapping_df['taxid'], errors='coerce').notna()]
        # Convert taxids to integers for consistent lookup
        mapping_df['taxid'] = mapping_df['taxid'].astype(int)
        return dict(zip(mapping_df['taxid'], mapping_df['phylum']))
    except Exception as e:
        print(f"Error loading mapping file: {e}")
        sys.exit(1)

def parse_assembly_file(assembly_file, taxid_mapping):
    """Parse the assembly file and extract phylum information."""
    print("Parsing assembly file...")

    phylum_counts = Counter()
    unmapped_taxids = set()
    unmapped_entries = []  # Store full entry information for unmapped taxids
    total_records = 0

    try:
        # Read the assembly file in chunks to handle large files
        chunk_size = 10000

        # First, count total lines for progress bar
        with open(assembly_file, 'r') as f:
            total_lines = sum(1 for line in f if not line.startswith('#'))

        with open(assembly_file, 'r') as f:
            # Skip header lines and capture the column headers
            header_line = None
            for line in f:
                if line.startswith('#assembly_accession'):
                    header_line = line.strip().lstrip('#')
                    break
                elif not line.startswith('#'):
                    break

            # Process data lines with progress bar
            with tqdm(total=total_lines, desc="Processing assembly records") as pbar:
                for line in f:
                    if line.strip():
                        total_records += 1
                        fields = line.strip().split('\t')

                        if len(fields) >= 8:  # Ensure we have enough fields for key information
                            try:
                                taxid = int(fields[5])  # taxid is in column 6 (0-indexed: 5)

                                if taxid in taxid_mapping:
                                    phylum = taxid_mapping[taxid]
                                    phylum_counts[phylum] += 1
                                else:
                                    unmapped_taxids.add(taxid)
                                    # Store key information for unmapped entries
                                    unmapped_entry = {
                                        'assembly_accession': fields[0] if len(fields) > 0 else '',
                                        'taxid': taxid,
                                        'species_taxid': fields[6] if len(fields) > 6 else '',
                                        'organism_name': fields[7] if len(fields) > 7 else '',
                                        'infraspecific_name': fields[8] if len(fields) > 8 else '',
                                        'isolate': fields[9] if len(fields) > 9 else '',
                                        'assembly_level': fields[11] if len(fields) > 11 else '',
                                        'genome_rep': fields[13] if len(fields) > 13 else '',
                                        'asm_name': fields[15] if len(fields) > 15 else ''
                                    }
                                    unmapped_entries.append(unmapped_entry)
                            except (ValueError, IndexError):
                                continue  # Skip malformed lines

                    pbar.update(1)

    except Exception as e:
        print(f"Error parsing assembly file: {e}")
        sys.exit(1)

    return phylum_counts, unmapped_taxids, unmapped_entries, total_records

def generate_report(phylum_counts, unmapped_taxids, total_records):
    """Generate and display the sanity check report."""
    print("\n" + "="*60)
    print("PHYLUM SANITY CHECK REPORT")
    print("="*60)
    
    print(f"Total assembly records processed: {total_records:,}")
    print(f"Records with mapped phylums: {sum(phylum_counts.values()):,}")
    print(f"Records with unmapped taxids: {len(unmapped_taxids):,}")
    print(f"Unique phylums found: {len(phylum_counts)}")
    print(f"Unique unmapped taxids: {len(unmapped_taxids)}")
    
    # Calculate mapping percentage
    mapped_records = sum(phylum_counts.values())
    mapping_percentage = (mapped_records / total_records) * 100 if total_records > 0 else 0
    print(f"Mapping success rate: {mapping_percentage:.2f}%")
    
    print("\n" + "-"*60)
    print("TOP 20 PHYLUMS BY GENOME COUNT:")
    print("-"*60)
    print(f"{'Phylum':<30} {'Count':<10} {'Percentage':<10}")
    print("-"*60)
    
    for phylum, count in phylum_counts.most_common(20):
        percentage = (count / mapped_records) * 100 if mapped_records > 0 else 0
        print(f"{phylum:<30} {count:<10,} {percentage:<10.2f}%")
    
    # Show some unmapped taxids for debugging
    if unmapped_taxids:
        print(f"\nFirst 10 unmapped taxids: {list(unmapped_taxids)[:10]}")
    
    return phylum_counts

def save_results(phylum_counts, unmapped_taxids, total_records, output_file):
    """Save the phylum counts to a CSV file with comprehensive statistics header."""
    print(f"\nSaving results to {output_file}...")

    # Calculate statistics
    mapped_records = sum(phylum_counts.values())
    unmapped_records = len(unmapped_taxids)
    mapping_percentage = (mapped_records / total_records) * 100 if total_records > 0 else 0
    unique_phylums = len(phylum_counts)

    # Create DataFrame with results
    results_df = pd.DataFrame([
        {'phylum': phylum, 'phylum_count': count}
        for phylum, count in phylum_counts.most_common()
    ])

    # Write file with statistics header
    with open(output_file, 'w') as f:
        # Write comprehensive statistics header
        f.write("# PHYLUM SANITY CHECK RESULTS\n")
        f.write("# Generated from NCBI Assembly Summary using taxid_to_phylum.csv mapping\n")
        f.write("#\n")
        f.write("# MAPPING STATISTICS:\n")
        f.write(f"# Total assembly entries processed: {total_records:,}\n")
        f.write(f"# Successfully mapped entries: {mapped_records:,}\n")
        f.write(f"# Unmapped entries (missing taxid): {unmapped_records:,}\n")
        f.write(f"# Mapping success rate: {mapping_percentage:.2f}%\n")
        f.write("#\n")
        f.write("# PHYLUM DIVERSITY:\n")
        f.write(f"# Total unique phylums found: {unique_phylums}\n")
        f.write(f"# Unique unmapped taxids: {len(unmapped_taxids)}\n")
        f.write("#\n")
        f.write("# TOP 10 PHYLUMS BY COUNT:\n")
        for i, (phylum, count) in enumerate(phylum_counts.most_common(10), 1):
            percentage = (count / mapped_records) * 100 if mapped_records > 0 else 0
            f.write(f"# {i:2d}. {phylum:<25} {count:>8,} ({percentage:5.2f}%)\n")
        f.write("#\n")
        f.write("# DATA COLUMNS: phylum, phylum_count\n")
        f.write("#\n")

        # Write CSV data
        f.write("phylum,phylum_count\n")
        for phylum, count in phylum_counts.most_common():
            f.write(f"{phylum},{count}\n")

    print(f"Results saved to {output_file}")
    print(f"File includes comprehensive statistics header with mapping details")

    return results_df

def save_unmapped_entries(unmapped_entries, output_dir):
    """Save unmapped assembly entries with full information for analysis."""
    if unmapped_entries:
        unmapped_file = output_dir / "phylum_unmapped_entries.csv"
        print(f"Saving {len(unmapped_entries)} unmapped entries to {unmapped_file}...")

        # Create DataFrame from unmapped entries
        unmapped_df = pd.DataFrame(unmapped_entries)

        # Sort by organism name for easier browsing
        unmapped_df = unmapped_df.sort_values('organism_name')

        # Add header with statistics and save
        with open(unmapped_file, 'w') as f:
            f.write("# UNMAPPED ASSEMBLY ENTRIES FROM PHYLUM SANITY CHECK\n")
            f.write(f"# Total unmapped entries: {len(unmapped_entries)}\n")
            f.write("# These entries were found in assembly file but their taxids are not in taxid_to_phylum.csv\n")
            f.write("#\n")
            f.write("# DATA COLUMNS: assembly_accession, taxid, species_taxid, organism_name, infraspecific_name, isolate, assembly_level, genome_rep, asm_name\n")
            f.write("#\n")

            # Write CSV data
            unmapped_df.to_csv(f, index=False)

        print(f"Unmapped entries saved to {unmapped_file}")

        # Show some examples
        print(f"\nFirst 5 unmapped organisms:")
        for i, entry in enumerate(unmapped_df.head().to_dict('records')):
            print(f"  {i+1}. {entry['organism_name']} (taxid: {entry['taxid']})")

    else:
        print("No unmapped entries to save")

def main():
    # Setup paths using flexible path handling
    script_dir = Path(__file__).resolve().parent

    # Create output directory if it doesn't exist (parent directory is 0_sanity_scriptres)
    output_dir = script_dir.parent / "phylum_sanity"
    output_dir.mkdir(exist_ok=True)

    # File paths (using relative paths from script location)
    # Go up to ncbi_parse level: script_dir -> 0_sanity_scriptres -> sanity_check -> metadata -> ncbi_parse
    ncbi_parse_dir = script_dir.parent.parent.parent.parent
    mapping_file = ncbi_parse_dir / "taxonomic_mapping" / "taxid_to_phylum.csv"
    assembly_file = ncbi_parse_dir / "metadata" / "00assembly_summary_genbank.txt"
    output_file = output_dir / "phylum_sanity_check_results.csv"
    
    print("Starting phylum sanity check...")
    print(f"Mapping file: {mapping_file}")
    print(f"Assembly file: {assembly_file}")
    print(f"Output file: {output_file}")
    
    # Load taxid to phylum mapping
    taxid_mapping = load_taxid_to_phylum_mapping(mapping_file)
    
    # Parse assembly file and count phylums
    phylum_counts, unmapped_taxids, unmapped_entries, total_records = parse_assembly_file(assembly_file, taxid_mapping)

    # Generate report
    phylum_counts = generate_report(phylum_counts, unmapped_taxids, total_records)

    # Save results
    results_df = save_results(phylum_counts, unmapped_taxids, total_records, output_file)

    # Save unmapped entries with full information for further analysis
    save_unmapped_entries(unmapped_entries, output_dir)

    print(f"\nSanity check completed successfully!")
    print(f"All output files saved in: {output_dir}/")
    print(f"- Main results: {output_file.name}")
    if unmapped_entries:
        print(f"- Unmapped entries: phylum_unmapped_entries.csv")

if __name__ == "__main__":
    main()
