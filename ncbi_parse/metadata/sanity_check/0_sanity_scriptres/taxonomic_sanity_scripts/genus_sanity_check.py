#!/usr/bin/env python3
"""
Genus sanity check script to parse assembly file and group by genus with counts.
Uses taxid_to_genus.csv as input for genus mapping.

Created: 2025-07-28 04:28:00
Last Modified: 2025-08-02 01:37:00
Author: Generated by Augment Agent

Purpose: Maps NCBI assembly entries to genus-level taxonomy and identifies unmapped entries.
"""

import pandas as pd
import sys
from collections import Counter
from tqdm import tqdm
from pathlib import Path

def load_taxid_to_genus_mapping(mapping_file):
    """Load the taxid to genus mapping from CSV file."""
    print("Loading taxid to genus mapping...")
    try:
        mapping_df = pd.read_csv(mapping_file)
        print(f"Loaded {len(mapping_df)} taxid mappings")
        # Filter out any non-numeric taxids (like header strings that might have been included)
        mapping_df = mapping_df[pd.to_numeric(mapping_df['taxid'], errors='coerce').notna()]
        # Convert taxids to integers for consistent lookup
        mapping_df['taxid'] = mapping_df['taxid'].astype(int)
        return dict(zip(mapping_df['taxid'], mapping_df['genus']))
    except Exception as e:
        print(f"Error loading mapping file: {e}")
        sys.exit(1)

def parse_assembly_file(assembly_file, taxid_mapping):
    """Parse the assembly file and extract genus information."""
    print("Parsing assembly file...")
    
    genus_counts = Counter()
    unmapped_taxids = set()
    unmapped_entries = []  # Store full entry information for unmapped taxids
    total_records = 0
    
    try:
        # First, count total lines for progress bar
        with open(assembly_file, 'r') as f:
            total_lines = sum(1 for line in f if not line.startswith('#'))
        
        with open(assembly_file, 'r') as f:
            # Skip header lines and capture the column headers
            header_line = None
            for line in f:
                if line.startswith('#assembly_accession'):
                    header_line = line.strip().lstrip('#')
                    break
                elif not line.startswith('#'):
                    break
            
            # Process data lines with progress bar
            with tqdm(total=total_lines, desc="Processing assembly records") as pbar:
                for line in f:
                    if line.strip():
                        total_records += 1
                        fields = line.strip().split('\t')
                        
                        if len(fields) >= 8:  # Ensure we have enough fields for key information
                            try:
                                taxid = int(fields[5])  # taxid is in column 6 (0-indexed: 5)
                                
                                if taxid in taxid_mapping:
                                    genus = taxid_mapping[taxid]
                                    genus_counts[genus] += 1
                                else:
                                    unmapped_taxids.add(taxid)
                                    # Store key information for unmapped entries
                                    unmapped_entry = {
                                        'assembly_accession': fields[0] if len(fields) > 0 else '',
                                        'taxid': taxid,
                                        'species_taxid': fields[6] if len(fields) > 6 else '',
                                        'organism_name': fields[7] if len(fields) > 7 else '',
                                        'infraspecific_name': fields[8] if len(fields) > 8 else '',
                                        'isolate': fields[9] if len(fields) > 9 else '',
                                        'assembly_level': fields[11] if len(fields) > 11 else '',
                                        'genome_rep': fields[13] if len(fields) > 13 else '',
                                        'asm_name': fields[15] if len(fields) > 15 else ''
                                    }
                                    unmapped_entries.append(unmapped_entry)
                            except (ValueError, IndexError):
                                continue  # Skip malformed lines
                    
                    pbar.update(1)
                    
    except Exception as e:
        print(f"Error parsing assembly file: {e}")
        sys.exit(1)
    
    return genus_counts, unmapped_taxids, unmapped_entries, total_records

def generate_report(genus_counts, unmapped_taxids, total_records):
    """Generate and display the sanity check report."""
    print("\n" + "="*60)
    print("GENUS SANITY CHECK REPORT")
    print("="*60)
    
    print(f"Total assembly records processed: {total_records:,}")
    print(f"Records with mapped genera: {sum(genus_counts.values()):,}")
    print(f"Records with unmapped taxids: {len(unmapped_taxids):,}")
    print(f"Unique genera found: {len(genus_counts)}")
    print(f"Unique unmapped taxids: {len(unmapped_taxids)}")
    
    # Calculate mapping percentage
    mapped_records = sum(genus_counts.values())
    mapping_percentage = (mapped_records / total_records) * 100 if total_records > 0 else 0
    print(f"Mapping success rate: {mapping_percentage:.2f}%")
    
    print("\n" + "-"*60)
    print("TOP 20 GENERA BY GENOME COUNT:")
    print("-"*60)
    print(f"{'Genus':<40} {'Count':<10} {'Percentage':<10}")
    print("-"*60)
    
    for genus, count in genus_counts.most_common(20):
        percentage = (count / mapped_records) * 100 if mapped_records > 0 else 0
        print(f"{genus:<40} {count:<10,} {percentage:<10.2f}%")
    
    # Show some unmapped taxids for debugging
    if unmapped_taxids:
        print(f"\nFirst 10 unmapped taxids: {list(unmapped_taxids)[:10]}")
    
    return genus_counts

def save_results(genus_counts, unmapped_taxids, unmapped_entries, total_records, output_file):
    """Save the genus counts to a CSV file with comprehensive statistics header."""
    print(f"\nSaving results to {output_file}...")
    
    # Calculate statistics
    mapped_records = sum(genus_counts.values())
    unmapped_records = len(unmapped_taxids)
    mapping_percentage = (mapped_records / total_records) * 100 if total_records > 0 else 0
    unique_genera = len(genus_counts)
    
    # Create DataFrame with results
    results_df = pd.DataFrame([
        {'genus': genus, 'genus_count': count}
        for genus, count in genus_counts.most_common()
    ])
    
    # Write file with statistics header
    with open(output_file, 'w') as f:
        # Write comprehensive statistics header
        f.write("# GENUS SANITY CHECK RESULTS\n")
        f.write("# Generated from NCBI Assembly Summary using taxid_to_genus.csv mapping\n")
        f.write("#\n")
        f.write("# MAPPING STATISTICS:\n")
        f.write(f"# Total assembly entries processed: {total_records:,}\n")
        f.write(f"# Successfully mapped entries: {mapped_records:,}\n")
        f.write(f"# Unmapped entries (missing taxid): {unmapped_records:,}\n")
        f.write(f"# Mapping success rate: {mapping_percentage:.2f}%\n")
        f.write("#\n")
        f.write("# GENUS DIVERSITY:\n")
        f.write(f"# Total unique genera found: {unique_genera}\n")
        f.write(f"# Unique unmapped taxids: {len(unmapped_taxids)}\n")
        f.write("#\n")
        f.write("# TOP 10 GENERA BY COUNT:\n")
        for i, (genus, count) in enumerate(genus_counts.most_common(10), 1):
            percentage = (count / mapped_records) * 100 if mapped_records > 0 else 0
            f.write(f"# {i:2d}. {genus:<35} {count:>8,} ({percentage:5.2f}%)\n")
        f.write("#\n")
        f.write("# DATA COLUMNS: genus, genus_count\n")
        f.write("#\n")
        
        # Write CSV data
        f.write("genus,genus_count\n")
        for genus, count in genus_counts.most_common():
            f.write(f"{genus},{count}\n")
    
    print(f"Results saved to {output_file}")
    print(f"File includes comprehensive statistics header with mapping details")
    
    return results_df

def save_unmapped_entries(unmapped_entries, output_dir):
    """Save unmapped assembly entries with full information for analysis."""
    if unmapped_entries:
        unmapped_file = output_dir / "genus_unmapped_entries.csv"
        print(f"Saving {len(unmapped_entries)} unmapped entries to {unmapped_file}...")
        
        # Create DataFrame from unmapped entries
        unmapped_df = pd.DataFrame(unmapped_entries)
        
        # Sort by organism name for easier browsing
        unmapped_df = unmapped_df.sort_values('organism_name')
        
        # Add header with statistics and save
        with open(unmapped_file, 'w') as f:
            f.write("# UNMAPPED ASSEMBLY ENTRIES FROM GENUS SANITY CHECK\n")
            f.write(f"# Total unmapped entries: {len(unmapped_entries)}\n")
            f.write("# These entries were found in assembly file but their taxids are not in taxid_to_genus.csv\n")
            f.write("#\n")
            f.write("# DATA COLUMNS: assembly_accession, taxid, species_taxid, organism_name, infraspecific_name, isolate, assembly_level, genome_rep, asm_name\n")
            f.write("#\n")
            
            # Write CSV data
            unmapped_df.to_csv(f, index=False)
        
        print(f"Unmapped entries saved to {unmapped_file}")
        
        # Show some examples
        print(f"\nFirst 5 unmapped organisms:")
        for i, entry in enumerate(unmapped_df.head().to_dict('records')):
            print(f"  {i+1}. {entry['organism_name']} (taxid: {entry['taxid']})")
            
    else:
        print("No unmapped entries to save")

def main():
    # Setup paths using flexible path handling
    script_dir = Path(__file__).resolve().parent

    # Create output directory if it doesn't exist (parent directory is 0_sanity_scriptres)
    output_dir = script_dir.parent / "genus_sanity"
    output_dir.mkdir(exist_ok=True)

    # File paths (using relative paths from script location)
    # Go up to ncbi_parse level: script_dir -> 0_sanity_scriptres -> sanity_check -> metadata -> ncbi_parse
    ncbi_parse_dir = script_dir.parent.parent.parent.parent
    mapping_file = ncbi_parse_dir / "taxonomic_mapping" / "taxid_to_genus.csv"
    assembly_file = ncbi_parse_dir / "metadata" / "00assembly_summary_genbank.txt"
    output_file = output_dir / "genus_sanity_check_results.csv"
    
    print("Starting genus sanity check...")
    print(f"Mapping file: {mapping_file}")
    print(f"Assembly file: {assembly_file}")
    print(f"Output file: {output_file}")
    
    # Load taxid to genus mapping
    taxid_mapping = load_taxid_to_genus_mapping(mapping_file)
    
    # Parse assembly file and count genera
    genus_counts, unmapped_taxids, unmapped_entries, total_records = parse_assembly_file(assembly_file, taxid_mapping)
    
    # Generate report
    genus_counts = generate_report(genus_counts, unmapped_taxids, total_records)
    
    # Save results
    results_df = save_results(genus_counts, unmapped_taxids, unmapped_entries, total_records, output_file)
    
    # Save unmapped entries with full information for further analysis
    save_unmapped_entries(unmapped_entries, output_dir)

    print(f"\nGenus sanity check completed successfully!")
    print(f"All output files saved in: {output_dir}/")
    print(f"- Main results: {output_file.name}")
    if unmapped_entries:
        print(f"- Unmapped entries: genus_unmapped_entries.csv")

if __name__ == "__main__":
    main()
